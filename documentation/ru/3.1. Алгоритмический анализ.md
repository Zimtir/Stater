# Алгоритмический анализ

Для понимания того, насколько ресурсоёмкими являются те или иные вычисления необходимо оценить сложность алгоритмов.

Сложность алгоритмов обычно оценивают по времени выполнения или по используемой памяти. В обоих случаях сложность зависит от размеров входных данных: массив из 100 элементов будет обработан быстрее, чем аналогичный из 1000. При этом точное время мало кого интересует: оно зависит от процессора, типа данных, языка программирования и множества других параметров. Важна лишь асимптотическая сложность, т. е. сложность при стремлении размера входных данных к бесконечности.

Допустим, некоторому алгоритму нужно выполнить&nbsp;<code>4n<sup>3</sup>&nbsp;+ 7n</code>&nbsp;условных операций, чтобы обработать&nbsp;<code>n</code>&nbsp;элементов входных данных. При увеличении&nbsp;<code>n</code>&nbsp;на итоговое время работы будет значительно больше влиять возведение&nbsp;<code>n</code>&nbsp;в куб, чем умножение его на&nbsp;<code>4</code>&nbsp;или же прибавление&nbsp;<code>7n</code>. Тогда говорят, что временная сложность этого алгоритма равна&nbsp;<code>О(n<sup>3</sup>)</code>, т. е. зависит от размера входных данных кубически.

Использование заглавной буквы О (или так называемая О-нотация) пришло из математики, где её применяют для сравнения асимптотического поведения функций. Формально&nbsp;<code>O(f(n))</code>&nbsp;означает, что время работы алгоритма (или объём занимаемой памяти) растёт в зависимости от объёма входных данных не быстрее, чем некоторая константа, умноженная на&nbsp;<code>f(n)</code>.
&nbsp;

<h2>Примеры</h2>
<h3>O(n) &mdash; линейная сложность</h3>
Такой сложностью обладает, например, алгоритм поиска наибольшего элемента в не отсортированном массиве. Нам придётся пройтись по всем&nbsp;<code>n</code>&nbsp;элементам массива, чтобы понять, какой из них максимальный.
<h3>O(log n) &mdash; логарифмическая сложность</h3>
Простейший пример &mdash; бинарный поиск. Если массив отсортирован, мы можем проверить, есть ли в нём какое-то конкретное значение, методом деления пополам. Проверим средний элемент, если он больше искомого, то отбросим вторую половину массива &mdash; там его точно нет. Если же меньше, то наоборот &mdash; отбросим начальную половину. И так будем продолжать делить пополам, в итоге проверим&nbsp;<code>log n</code>&nbsp;элементов.
<h3>O(n<sup>2</sup>) &mdash; квадратичная сложность</h3>
Такую сложность имеет, например, алгоритм сортировки вставками. В канонической реализации он представляет из себя два вложенных цикла: один, чтобы проходить по всему массиву, а второй, чтобы находить место очередному элементу в уже отсортированной части. Таким образом, количество операций будет зависеть от размера массива как&nbsp;<code>n * n</code>, т. е.&nbsp;<code>n<sup>2</sup></code>.
Бывают и другие оценки по сложности, но все они основаны на том же принципе.
Также случается, что время работы алгоритма вообще не зависит от размера входных данных. Тогда сложность обозначают как&nbsp;<code>O(1)</code>. Например, для определения значения третьего элемента массива не нужно ни запоминать элементы, ни проходить по ним сколько-то раз. Всегда нужно просто дождаться в потоке входных данных третий элемент и это будет результатом, на вычисление которого для любого количества данных нужно одно и то же время.
Аналогично проводят оценку и по памяти, когда это важно. Однако алгоритмы могут использовать значительно больше памяти при увеличении размера входных данных, чем другие, но зато работать быстрее. И наоборот. Это помогает выбирать оптимальные пути решения задач исходя из текущих условий и требований.

Так как, в данной системе преимущественно используется генетический алгоритм, то следует оценить его производительность, как функции большого поиска, что не составляет большого труда, так как скорость выполнения напрямую зависит от объемов данных и необходимой задданой скорости для их обработки, что позволяет использовать асимптотическую оценку, как основную.

Генетические алгоритмы (ГА) – это мощный инструмент для решения сложных задач. Они нашли применение в оптимизации, искусственном интеллекте, инженерии и других областях. В основе ГА лежат принципы, заимствованные из биологии и генетики. Напомним: основная идея ГА состоит в создании популяции особей (индивидов), каждая из которых представляется в виде хромосомы. Любая хромосома есть возможное решение рассматриваемой оптимизационной задачи. Для поиска лучших решений необходимо только значение целевой функции, или функции приспособленности. Значение функции приспособленности особи показывает, насколько хорошо подходит особь, описанная данной хромосомой, для решения задачи. Хромосома состоит из конечного числа генов, представляя генотип объекта, т.е. совокупность его наследственных признаков. Процесс эволюционного поиска ведется только на уровне генотипа. К популяции применяются основные биологические операторы: скрещивания, мутации, инверсии и др. В процессе эволюции действует известный принцип "выживает сильнейший". Популяция постоянно обновляется при помощи генерации новых особей и уничтожения старых, и каждая новая популяция становится лучше и зависит только от предыдущей.

Таким образом, для использования генетического алгоритма относительно статистических данных экономических регионов, мы можем утвердить, к примеру, наименование региона и количество инвестиций за определённый период, как один и тот же ресурс, расположенный в линейном пространстве, за хромосомы обозначить те инвестиционные фонды, в которые осуществляется поток денежных средств.
Для предсказания поведения одного экономического региона по отношению к другому спустя определённое количество времени и учитывая затраты на ресурсы, можно смело оценить то, когда один экономический регион способен обогнать другой по определённым показателям с определённой вероятности и учётом различных отклонений от вектора развитий, используя мутационную изменчивость.
Данная технология позволяет правильно распределять ресурсы между экономическими субъектами, чтобы повысить их эффективности при любом раскладе ресурсов и условиях внешней среды.

Как известно, высокая эффективность отыскания глобального минимума или максимума генетическим алгоритмом с двоичным кодированием теоретически обоснована в фундаментальной теореме генетических алгоритмов ("теореме о шаблоне"), доказанной Холландом. Ее подробное освещение и доказательство можно найти в соответствующих источниках. Ее суть в том, что двоичный алфавит позволяет обрабатывать максимальное количество информации по сравнению с другими схемами кодирования.
